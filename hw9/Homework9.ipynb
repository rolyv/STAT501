{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "a) The SLR models based on each single predictor, as well as the matrix plot below, indicate that the best linear predictors for Y are $x_1$, $x_3$, $x_4$, and $x_7$.\n",
    "\n",
    "[Insert matrix plot infection risk]\n",
    "\n",
    "b) The \"best\" stepwise model selected the same 4 predictors from part (a). \n",
    "\n",
    "[Insert stepwise model]\n",
    "\n",
    "c) Best subset: [insert best subset]\n",
    "\n",
    "    i.  Of the two 4-predictor models listed, there was a very small difference in terms of their adjusted $R^2$ and $C_p$ criterion. The better of the two was the model consisting of $x_1$, $x_3$, $x_4$, and $x_7$.\n",
    "    ii. Of the two 5-predictor models listed, there was again a very small difference in terms of their adjusted $R^2$ and $C_p$ criterion. The better of the two was the model consisting of $x_1$, $x_3$, $x_4$, $x_6$, and $x_7$.\n",
    "    \n",
    "d) The test here is whether $\\beta_6 = 0$. $H_0: \\beta_6 = 0, H_a: \\beta_6 \\ne 0$\n",
    "\n",
    "$df_R = n - p = 97 - 5 = 92$ <br>\n",
    "$MSE_R = S_R^2 = 0.91381^2 \\approx 0.83505$ <br>\n",
    "$SSE_R = MSE_R * (n - p) = 0.83505 * (97 - 5) \\approx 76.8245$ <br>\n",
    "\n",
    "$df_F = n - p = 97 - 6 = 91$ <br>\n",
    "$MSE_F = S_F^2 = 0.91323^2 \\approx 0.833989$ <br>\n",
    "$SSE_F = MSE_F * (n - p) = 0.833989 * (97 - 6) \\approx 75.8930$ <br>\n",
    "\n",
    "$F^* = \\frac{SSE_R - SSE_F}{df_R - df_F} \\div \\frac{SSE_F}{df_F} = \\frac{76.8245 - 75.8930}{92 - 91} \\div \\frac{75.8930}{91} = 1.11692$ <br>\n",
    "$p$-value $= 1 - 0.706616 = 0.293384$ \n",
    "\n",
    "Therefore, we fail to reject the null hypothesis and conclude that $x_6$ is not a significant predictor of Y and can be removed from the model that already contains $x_1$, $x_3$, $x_4$, and $x_7$.\n",
    "\n",
    "e) \n",
    "\n",
    "    i.  Based on the stepwise and best subsets procedures, it looks like either $x_1$ or $x_3$ would be the most significant predictor. Out of the 13 models listed in the best subsets output, $x_3$ appears in 12 of them, whereas $x_1$ appears in 11 of them. $x_1$ was the strongest individual predictor, so if I had to choose one, I would say $x_1$ is the most significant.\n",
    "    ii. The \"best\" model that includes predictor $x_6$ is the model that consists of $x_1$, $x_3$, $x_4$, $x_6$, and $x_7$. It has the highest adjusted $R^2$ value and lowest S value. It also has a good $C_p$ value less than $p$. \n",
    "\n",
    "f) Some useful information found in the Stepwise procedure that is not found in the Best Subsets procedure, is the value of the coefficients and the *p*-value of each parameter at each step of the process. Therefore, you can see the effect of the addition (or removal) of another parameter on the *p*-value of a given parameter. \n",
    "\n",
    "Some useful information found in the Best Subsets procedure that is not available in the Stepwise procedure is that it gives a \"larger picture\" of possible models that are worth evaluating. The Stepwise procedure seems a little more narrow in its output, where it basically gives a single \"recommendation\". The minitab output for Stepwise basically shows 4 candidate models, whereas the Best Subsets output shows 13. \n",
    "\n",
    "g) The \"best\" model with interaction effects chosen by the Stepwise procedure was the model that consists of $x_1$, $x_3$, $x_4$, and $x_7$ plus the addition of the interaction term $x_3*x_7$.\n",
    "\n",
    "h) $C_p = p + \\frac{(MSE_p - MSE_{all})(n - p)}{MSE_{all}} = 6 + \\frac{(.7380 - .7514)(97 - 6)}{.7514} = 4.37716$\n",
    "\n",
    "Based on this value of $C_p$, it is unbiased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "a) Model A: $R_{adj}^2 = 1 - \\left(\\frac{n-1}{n-p}\\right)\\frac{SSE_p}{SSTO} = 1 - \\left(\\frac{99}{95}\\right)\\frac{1300}{5200} = 0.73947$\n",
    "\n",
    "Model B: $R_{adj}^2 = 1 - \\left(\\frac{n-1}{n-p}\\right)\\frac{SSE_p}{SSTO} = 1 - \\left(\\frac{99}{94}\\right)\\frac{1210}{5200} = 0.75493$\n",
    "\n",
    "b) Model A: $AIC_p = n\\ln(SSE_p) - n\\ln(n) + 2p = 100\\ln(1300) - 100\\ln(100) + 2(5) = 266.4949$ <br>\n",
    "$BIC_p = n\\ln(SSE_p) - n\\ln(n) + p\\ln(n) = 100\\ln(1300) - 100\\ln(100) + 5\\ln(100) = 279.5208$\n",
    "\n",
    "Model B: $AIC_p = n\\ln(SSE_p) - n\\ln(n) + 2p = 100\\ln(1210) - 100\\ln(100) + 2(6) = 261.3206$ <br>\n",
    "$BIC_p = n\\ln(SSE_p) - n\\ln(n) + p\\ln(n) = 100\\ln(1210) - 100\\ln(100) + 6\\ln(100) = 276.9516$\n",
    "\n",
    "c) $MSE_{all} = \\frac{SSE_{all}}{n - p} = \\frac{1150}{100-11} = 12.9213$\n",
    "\n",
    "Model A: $C_p = \\frac{SSE_p}{MSE_{all}} - (n - 2p) = \\frac{1300}{12.9213} - (100 - 2*5) = 10.6091$ \n",
    "\n",
    "Model B: $C_p = \\frac{SSE_p}{MSE_{all}} - (n - 2p) = \\frac{1210}{12.9213} - (100 - 2*6) = 5.6438$\n",
    "\n",
    "The $C_p$ value of Model A is not desirable since it's double the value of *p*, it indicates bias. The $C_p$ value of Model B is near to the value of *p* which is desirable. \n",
    "\n",
    "d) Model B looks to be the preferable model across all criteria. It has a slightly higher adjusted $R^2$ value and slightly lower information criterion values. However, I think the $C_p$ is the deciding factor in the comparison. The $C_p$ value for Model A is almost double the number of parameters while it's near the value of *p* for Model B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "a)\n",
    "\n",
    "| Vars | R-sq   | R-sq (adj) | Mallows' $C_p$ |  S   | 1 | 2 | 3 | 4 |\n",
    "|------|--------|------------|----------------|------|---|---|---|---|\n",
    "| 1    | 68.411 | 67.753     | 2.082          |2.413 |   |   | X |   |\n",
    "| 1    | 64.184 | 63.438     | 8.516          |2.569 |   | X |   |   |\n",
    "| 2    | 70.332 | 69.070     | 1.157          |2.363 |   | X | X |   |\n",
    "| 2    | 69.112 | 67.797     | 3.015          |2.411 |   |   | X | X |\n",
    "| 3    | 70.434 | 68.506     | 3.003          |2.385 | X | X | X |   |\n",
    "| 3    | 70.366 | 68.434     | 3.106          |2.387 |   | X | X | X |\n",
    "| 4    | 70.434 | 67.806     | 5.003          |2.411 | X | X | X | X |\n",
    "\n",
    "b) From the table in part (a), we can see that the models are all very close in terms of their R-sq values and being unbiased models (with the exception of row 2). Starting from the model consisting of $x_3$, there was marginal improvement by adding $x_2$ to it. Without having any additional context about the purpose of the model, this seems like one of those situations where it would be best to opt for the simpler model since it doesn't look like there is much benefit from choosing a more complicated model. So from that point of view, I would conclude that the model consisting of the single predictor $x_3$, would be the \"best\" choice of those listed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
